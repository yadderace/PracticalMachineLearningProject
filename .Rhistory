g <- g + xlab("Fitting approach");
g <- g + ylab("Residual Price");
g;
g <- ggplot(data.frame(e = e, fit = fit), aes(y = e, x = fit, fill = fit));
g <- g + geom_dotplot(binaxis = "y", stackdir = "center", binwidth = 0.3);
g <- g + xlab("Fitting approach");
g <- g + ylab("Residual Price");
g;
g <- ggplot(data.frame(e = e, fit = fit), aes(y = e, x = fit, fill = fit));
g <- g + geom_dotplot(binaxis = "y", stackdir = "center", binwidth = 20);
g <- g + xlab("Fitting approach");
g <- g + ylab("Residual Price");
g;
g <- ggplot(data.frame(e = e, fit = fit), aes(y = e, x = fit, fill = fit));
g <- g + geom_dotplot(binaxis = "y", stackdir = "center", binwidth = 10);
g <- g + xlab("Fitting approach");
g <- g + ylab("Residual Price");
g;
g <- ggplot(data.frame(e = e, fit = fit), aes(y = e, x = fit, fill = fit));
g <- g + geom_dotplot(binaxis = "y", stackdir = "center", binwidth = 20);
g <- g + xlab("Fitting approach");
g <- g + ylab("Residual Price");
g;
y <- diamond$price;
x <- diamond$carat;
data(diamond)
library(UsingR)
data("diamond")
y <- diamond$price;
x <- diamond$carat;
fit <- lm(y ~ x);
coeffs <- summary(fit)$coefficients;
intervalBeta0 <- coeffs[1,1] + c(1,-1) * qt(0.975, df = fit$df) * coeffs[1,2];
intervalBeta1 <- coeffs[2,1] + c(1,-1) * qt(0.975, df = fit$df) * coeffs[2,2];
intervalBeta0
intervalBeta1
fit$df
length(y)
qt(0.975, df = 46)
qt(1)
qt(1, df)
qt(1, df=48)
qt(0.975, df=48)
qt?
d
?qt
qt(0.975, df=46)
(3885.651 + 3556.398)/2
3885.651 - (3885.651 + 3556.398)/2
newx <- data.frame(x = seq(min(x), max(x), length = 100));
p1 <- data.frame(predict(fit, newdata = newx, interval = ("confidence")));
p2 <- data.frame(predict(fit, newdata = newx, interval = ("prediction")));
p1$interval <- "confidence";
p2$interval <- "prediction";
p1$x <- newx$x;
p2$x <- newx$x;
dat <- rbind(p1, p2);
names(dat)[1] <- "y";
dat
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2);
newx <- data.frame(x = seq(min(x), max(x), length = 100));
p1 <- data.frame(predict(fit, newdata = newx, interval = ("confidence")));
p2 <- data.frame(predict(fit, newdata = newx, interval = ("prediction")));
p1$interval <- "confidence";
p2$interval <- "prediction";
p1$x <- newx$x;
p2$x <- newx$x;
dat <- rbind(p1, p2);
names(dat)[1] <- "y";
g <- ggplot(dat, aes(x = x, y = y));
g <- g + geom_line();
g <- g + geom_point(data = data.frame(x = x, y = y), aes(x =x, y = y), size = 4);
g <- geom_ribbon(aes(ymin = lwr, ymax = upr, fill = interval), alpha = 0.2);
g;
library(ggplot2);
newx <- data.frame(x = seq(min(x), max(x), length = 100));
p1 <- data.frame(predict(fit, newdata = newx, interval = ("confidence")));
p2 <- data.frame(predict(fit, newdata = newx, interval = ("prediction")));
p1$interval <- "confidence";
p2$interval <- "prediction";
p1$x <- newx$x;
p2$x <- newx$x;
dat <- rbind(p1, p2);
names(dat)[1] <- "y";
g <- ggplot(dat, aes(x = x, y = y));
g <- g + geom_line();
g <- g + geom_point(data = data.frame(x = x, y = y), aes(x =x, y = y), size = 4);
g <- g + geom_ribbon(aes(ymin = lwr, ymax = upr, fill = interval), alpha = 0.2);
g;
x <- c(0.61, 0.93, 0.83, 0.35, 0.54, 0.16, 0.91, 0.62, 0.62)
y <- c(0.67, 0.84, 0.6, 0.18, 0.85, 0.47, 1.1, 0.65, 0.36)
fit <- lm (y~x)
fit$coefficients
summary(fit)$coefficients
beta1 <- cor(y,x) * sd(y) / sd(x);
beta0 <- mean(y) - beta1 * mean(x);
e <- y - beta0 - beta1 * x;
sigma_2 <- sum(e^2)/(n-2);
sigma_2
sigma_2 <- sqrt(sum(e^2)/(n-2));
sigma <- sqrt(sum(e^2)/(n-2));
sigma
summary(fit)$sigma
beta1 <- cor(y,x) * sd(y) / sd(x);
beta0 <- mean(y) - beta1 * mean(x);
e <- y - beta0 - beta1 * x;
sum(e^2)/(length(y)-2)
sqrt(sum(e^2)/(length(y)-2))
data("mtcars")
fit <- lm(mpg~weight, mtcars)
fit <- lm(mpg~weigth, mtcars)
mtcars
fit <- lm(mpg~wt, mtcars)
fit <- lm(mpg~I(wt-mean(wt)), mtcars)
coeffs <- summary(fit)$coefficients;
intervalBeta0 <- coeffs[1,1] + c(1,-1) * qt(0.95, df = fit$df) * coeffs[1,2];
intervalBeta0
coeffs
fit$df
intervalBeta0
fit <- lm(mpg~wt, mtcars)
p1 <- data.frame(predict(fit, newdata = c('3'), interval = ("confidence")));
newx <- data.frame(x = c(3));
p1 <- data.frame(predict(fit, newdata = newx, interval = ("confidence")));
newx <- data.frame(wt = c(3));
p1 <- data.frame(predict(fit, newdata = newx, interval = ("confidence")));
p1 <- data.frame(predict(fit, newdata = newx, interval = ("prediction")));
p1
p1 <- data.frame(predict(fit, newdata = newx, interval = ("confidence")));
p1
newx <- data.frame(wt = c(1));
p1 <- data.frame(predict(fit, newdata = newx, interval = ("confidence")));
p1
newx <- data.frame(wt = c(2));
p1 <- data.frame(predict(fit, newdata = newx, interval = ("prediction")));
p1
newx <- data.frame(wt = c(4));
p1 <- data.frame(predict(fit, newdata = newx, interval = ("prediction")));
p1
9.527355-20.12811
fit <- lm(mpg~I(wt/2), mtcars)
summary(fit)$coefficients
newx <- data.frame(wt = c(1));
p1 <- data.frame(predict(fit, newdata = newx, interval = ("confidence")));
p1
newx <- data.frame(wt = c(2));
p1 <- data.frame(predict(fit, newdata = newx, interval = ("confidence")));
p1
29.18042 - 24.82389
library("swirl")
ls()
rm(list=ls())
clear
library("swirl")
swirl()
plot(child ~ parent, galton)
plot(jitter(child, 4) ~ parent, galton)
regrline <- lm(child ~ parent, galton)
abline(regrline, lwd=3, col='red')
summary(regrline)
fit <- lm(child ~ parent, galton)
summary(fit)
mean(fit$residuals)
cov(fit$residuals, galton$parent)
library(swirl)
swirl()
6
dim(InsectSprays)
HEAD(InsectSprays)
head(InsectSprays)
head(InsectSprays, 15)
sa
SA
sA
summar(InsectSprays[,2])
summary(InsectSprays[,2])
sapply(InsectSprays, class)
fit <- lm(count~spray, InsectSprays)
fit$coef
summary(fit)$coef
est <- summary(fit)$coef[,1]
mean(sA)
mean(sB)
nfit <- lm(count ~ spray - 1)
nfit <- lm(count ~ spray - 1, InsectSprays)
summary(nfit)$coef
spray2 <- relevel(InsectSprays$spray, "c")
spray2 <- relevel(InsectSprays$spray, c)
spray2 <- relevel(InsectSprays$spray, "C")
fit2 <- lm(count~spray, InsectSprays)
fit2 <- lm(count~spray2, InsectSprays)
summary(fit2)$coef
mean(sC)
(fit$coef[2] -fit$coef[3])/1.6011
dim(hunger)
948
names(hunger)
fit <- lm(Numeric~Year, hunger)
summary(fit)$coef
lmF <- lm(Count~Year, hunger[hunger$Sex=="Female"])
lmF <- lm(Count~Year, hunger[hunger$Sex=="Female"])
hunger$Sex
lmF <- lm(Count[Sex=="Female"~Year[Sex=="Female"], hunger)
lmF <- lm(Numeric[Sex=="Female"~Year[Sex=="Female"], hunger)
lmF<-lm(Numeric[Sex=="Female"~Year[Sex=="Female"],hunger)
lmF<-lm(Numeric[Sex=="Female"]~Year[Sex=="Female"],hunger)
lmM<-lm(Numeric[Sex=="Male"]~Year[Sex=="Male"],hunger)
lmBoth <- lm(Count~Year+Sex, hunger)
lmBoth <- lm(Numeric~Year+Sex, hunger)
summary(lmBoth)
lmInter <- lm(Numeric~Year+Sex+Sex*Year, hunger)
summary(lmInter)
ols.ic <- fit$coef[1]
ols.slope <- fit$coef[2]
lhs - rhs
all.equal(lhs, rhs)
varChild <- var(mch)
varChild
1
varChild <- var(galton$child)
varRes <- fit$residuals
varRes <- var(fit$residuals)
varEst <- var(est(ols.slope, ols.ic))
all.equal(varChild, varRes)
all.equal(varChild, varRes + varEst)
efit <- lm(accel ~ mag + dist, attenu)
mean(efit$residuals)
cov(efit$residuals, attenu$mag)
cov(efit$residuals, attenu$dist)
library(swirl)
swirl()
fit <- lm(y~x, out2)
plot(fit, which=2)
plot(fit, which=1)
fitno <- out2[-1,]
fitno <- lm(y~x, out2[-1,])
plot(fitno, which=1)
coef(fit) - coef(fitno)
head(dfbeta(fit))
resno <- out2[1, "y"] - predict(fitno, out2[1,])
1 - resid(fit)[1]/resno
head(hatvalues(fit))
sigma <- sum(out2$x ^ 2)
sigma <- sqrt(deviance(fit)/df.residual(fit))
rstd <- resid(fit) /(sigma * sqrt(1 - hatvalues(fit)))
head(cbind(rstd, rstandard(fit)))
plot(fit, which=3)
plot(fit, which=2)
sigma1 <- sqrt(deviance(fitno)/df.residual(fitno))
resid(fit)[1] /(sigma * sqrt(1 - hatvalues(fit)[1]))
resid(fit)[1] /(sigma1 * sqrt(1 - hatvalues(fit)[1]))
head(rstudent(fit))
dy <- predict(fitn, out2) - predict(fit, out2)
dy <- predict(fitno, out2) - predict(fit, out2)
sum(dy ^2) / (2 * sigma ^ 2)
plot(fit, which = 5)
library(swirl)
swirl()
rgp1()
rgp2()
head(swiss)
md1 <- lm(Fertility ~ ., swiss)
mdl <- lm(Fertility ~ ., swiss)
vif(md1)
vif(mdl)
mdl2 <- lm(Fertility ~ Agriculture + Education + Catholic + Infant.Mortality, swiss)
vif(mdl2)
x1c <- simbias()
apply(x1c, 1, mean)
fit1 <- lm(Fertility ~ Agriculture, swiss)
fit3 <- lm(Fertility ~ Agriculture + Examination + Education, swiss)
anova(fit1, fi3)
anova(fit1, fit3)
deviance(fit3)
d <- deviance(fit3)/43
n <- (deviance(fit1) - deviance(fit3))/2
n/d
pf(n/d, 2, 43, lower.tail = FALSE)
shapiro.test(fit3$residuals)
anova(fit1, fit3, fit5, fit6)
View(ravenData)
mdl <- glm(ravenNum ~ ravenScore, family = 'binomial', ravenData)
mdl <- glm(ravenWinNum ~ ravenScore, family = 'binomial', ravenData)
predict(mdl, data.frame(ravenScore = c(0,3,6)))
lodds<-predict(mdl, data.frame(ravenScore = c(0,3,6)))
exp(lodds)/(1+expo(lodds))
exp(lodds)/(1+exp(lodds))
summary(mdl)
exp(confint(mdl))
anova(mdl)
qchisq(0.95,1)
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2);
cor(mtcars)
cor(mtcars)[1,]
round(cor(mtcars)[1,],2)
mdl2 <- lm(mpg ~ am + cyl + disp + hp + wt)
mdl2 <- lm(mpg ~ am + cyl + disp + hp + wt, data = mtcars)
summary(mdl2)
summary(mdl1);
mdl1 <- lm(mpg~am, data = mtcars);
mdl1 <- lm(mpg~am, data = mtcars);
summary(mdl1);
p <- ggplot(mtcars, aes(x = am, y = mpg))
p + geom_boxplot()
p <- ggplot(mtcars, aes(x = am, y = mpg, fill = am))
p + geom_boxplot()
mtcars$am <- factor(mtcars$am)
p <- ggplot(mtcars, aes(x = am, y = mpg, fill = am))
p + geom_boxplot()
mtcars$am <- factor(mtcars$am, levels = c(1,0), labels = c("Manual", "Automatic"))
p <- ggplot(mtcars, aes(x = am, y = mpg, fill = am))
p + geom_boxplot()
mtcars$am <- factor(mtcars$am, levels = c(1,0), labels = c("Manual", "Automatic"))
p <- ggplot(mtcars, aes(x = am, y = mpg, fill = am))
p + geom_boxplot() + labs(title = "Miles per gallon by transmission")
mtcars$am <- factor(mtcars$am, levels = c(1,0), labels = c("Manual", "Automatic"))
p <- ggplot(mtcars, aes(x = am, y = mpg, fill = am))
p + geom_boxplot() + labs(X = "Transmission")
mtcars$am <- factor(mtcars$am, levels = c(1,0), labels = c("Manual", "Automatic"))
p <- ggplot(mtcars, aes(x = am, y = mpg, fill = am)) + labs(X = "Transmission")
p + geom_boxplot()
mtcars$am <- factor(mtcars$am, levels = c(1,0), labels = c("Manual", "Automatic"))
p <- ggplot(mtcars, aes(x = am, y = mpg, fill = am))
p + geom_boxplot()
mtcars$am <- factor(mtcars$am, levels = c(1,0), labels = c("Manual", "Automatic"))
p <- ggplot(mtcars, aes(x = am, y = mpg, fill = am))
p + geom_boxplot()
p <- ggplot(mtcars, aes(x = am, y = mpg, fill = am))
p + geom_boxplot()
data("mtcars");
#Creating factor variable for am.
mtcars$am <- factor(mtcars$am, levels = c(1,0), labels = c("Manual", "Automatic"))
head(mtcars);
p <- ggplot(mtcars, aes(x = am, y = mpg, fill = am))
p + geom_boxplot()
p <- ggplot(mtcars, aes(x = am, y = mpg, fill = am))
p + geom_boxplot() + labs(title = "Miles per gallon by transmission")
p <- ggplot(mtcars, aes(x = am, y = mpg, fill = am))
p + geom_boxplot() + labs(title = "Miles per gallon by transmission", x = "Transmission", y = "Miles per gallon")
mdl1 <- lm(mpg~am, data = mtcars);
summary(mdl1);
mean(subset(mtcars, am = 1)$mpg) - mean(subset(mtcars, am = 0)$mpg)
mean(subset(mtcars, am = 0)$mpg)
mean(subset(mtcars, am = 1)$mpg)
mean(subset(mtcars, am = "Manual")$mpg) - mean(subset(mtcars, am = "Automatic")$mpg)
subset(mtcars, am = "Automatic")
subset(mtcars, am = 1)
subset(mtcars, am == 1)
mean(mtcars[am = 1])
mean(mtcars[am = 1,])
mean(mtcars[am = 1,]$mpg)
mean(mtcars[am = "Automatic",]$mpg)
mean(mtcars[am == "Automatic",]$mpg)
mean(mtcars[am == factor("Automatic"),]$mpg)
mtcars
mtcars[am = "Manual"]
mtcars[am = "Manual",]
mtcars[mtcars$am = "Manual",]
mtcars[mtcars$am == "Manual",]
mtcars[mtcars$am == 1,]
mtcars[mtcars$am == "Manual",]
mean(mtcars[mtcars$am == "Manual"]$mpg) - mean(mtcars[mtcars$am == "Automatic"]$mpg)
mean(mtcars[mtcars$am == "Manual",]$mpg) - mean(mtcars[mtcars$am == "Automatic",]$mpg)
# Correlation values for mpg with another variables from the same dataset.
round(cor(mtcars)[1,],2)
mtcars$am <- as.numeric(levels(mtcars$am))
# Correlation values for mpg with another variables from the same dataset.
round(cor(mtcars)[1,],2)
round(cor(mtcars[sapply(mtcars, is.numeric)])[1,],2)
round(cor(mtcars[sapply(mtcars, is.numeric),])[1,],2)
anova(mdl1, mdl2)
plot(mdl2)
par(mfrow=c(2, 2))
plot(mdl2)
# Correlation values for mpg with another variables from the same dataset.
round(cor(mtcars[sapply(mtcars, is.numeric),])[1,],2)
# Correlation values for mpg with another variables from the same dataset.
round(cor(mtcars[sapply(mtcars, is.numeric),])[1,],2)
# Correlation values for mpg with another variables from the same dataset.
round(cor(mtcars[sapply(mtcars, is.numeric),])[1,],2)
# Correlation values for mpg with another variables from the same dataset.
round(cor(mtcars)[1,],2)
mtcars[,"am"]
mtcars
library(ggplot2);
data("mtcars");
mtcars
mtcars$am <- factor(mtcars$am, levels = c(0, 1), labels = c("Automatic", "Manual"))
mtcars
head(mtcars);
round(cor(mtcars)[1,],2)
mtcars
mtcars[,"am"]
mtcars[,-"am"]
mtcars[,-am]
mtcars[,am]
mtcars[,"am"]
mtcars[,c("am")]
mtcars[,-c("am")]
mtcars[,names(mtcars) != "am"]
# Correlation values for mpg with another variables from the same dataset.
round(cor(mtcars[,names(mtcars) != "am"])[1,],2)
mdl2 <- lm(mpg ~ am + cyl + disp + hp + wt, data = mtcars)
summary(mdl2)
summary(mdl1)$coef;
mdl2 <- lm(mpg ~ am + cyl + disp + hp + wt, data = mtcars)
summary(mdl2)$coef
install.packages("caret")
library(AppliedPredictiveModeling)
library(AppliedPredictiveModeling)
install.packages("AppliedPredictiveModeling")
library(AppliedPredictiveModeling)
data("segmentationOriginal")
library(caret)
library("caret")
install.packages("caret")
library("caret")
install.packages("rlang")
library("caret")
install.packages("dplyr")
library("caret")
head(segmentationOriginal)
inTrain <- createDataPartition(y = segmentationOriginal$Case, p = 0.7, list = FALSE)
head(inTrain)
training <- segmentationOriginal[inTrain,]
head(training)
testing <- segmentationOriginal[-inTrain,]
nrow(testing)
nrow(training)
set.seed(125)
modFit <- train(Class~., method = "rpart", data = training)
modFit$finalModel
library(rattle)
install.packages(rattle)
library(rpart.plot)
library(rpart)
install.packages(pgmm)
install.packages("pgmm")
library(pgmm)
data("olive")
head(olive)
olive <- olive[,-1]
head(olive)
train <- (Area ~ ., method = "rpart", data = olive)
modFit <- train(Area ~ ., method = "rpart", data = olive)
newData <- as.data.frame(t(colMeans(olive)))
head(newData)
?t
colMeans(olive)
t(colMeans(olive))
predict(modFit, newData)
install.packages("ElemStatLearn")
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
library(SAheart)
library(ElemStatLearn)
data("SAheart")
set.seed(8484)
dim(SAheart)
dim(SAheart)[1]
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
dim(train)
head(train)
nrow(train)
train
trainSA <- SAheart[train,]
testSA <- SAheart[-train,]
nrow(trainSA)
nrow(testSA)
set.seed(13234)
modelSA <- train(chd ~ age + alcohol + obesity + tobacco + typea + ldl,
data = trainSA, method = "glm", family = "binomial")
missClass(testSA$chd, predict(modelSA, newdata = testSA))
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
missClass(testSA$chd, predict(modelSA, newdata = testSA))
missClass(testSA$chd, predict(modelSA, newdata = trainSA))
set.seed(13234)
modelSA <- train(chd ~ age + alcohol + obesity + tobacco + typea + ldl, data = trainSA, method = "glm", family = "binomial")
missClass(testSA$chd, predict(modelSA, newdata = testSA))
missClass(testSA$chd, predict(modelSA, newdata = trainSA))
setwd("C:/Users/yadde/Documents/CourseraAssignments/8 Practical Machine Lerning/Final Assignment")
knitr::opts_chunk$set(echo = TRUE)
training <- read.csv("pml-training.csv")
testing <- read.csv("pml-testing.csv")
View(training)
# Checking dimensions
dim(training)
training <- read.csv("pml-training.csv")
testing <- read.csv("pml-testing.csv")
# Checking dimensions
dim(training)
dim(testing)
inTrain <- createDataPartition(training, p = 0.6, list = FALSE)
library(caret)
inTrain <- createDataPartition(training, p = 0.6, list = FALSE)
inTrain <- createDataPartition(training$classe, p = 0.6, list = FALSE)
View(inTrain)
inTrain <- createDataPartition(training$classe, p = 0.6, list = FALSE)
set.seed(12345)
inTrain <- createDataPartition(training$classe, p = 0.6, list = FALSE)
set.seed(12345)
inTrain <- createDataPartition(training$classe, p = 0.7, list = FALSE)
myTraining <- training[inTrain,]
myTesting <- training[-inTrain,]
# Checking dimensions
dim(myTraining)
dim(myTesting)
